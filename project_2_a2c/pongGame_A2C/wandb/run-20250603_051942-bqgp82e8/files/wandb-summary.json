{"update": 1999, "total_loss": 0.3257910907268524, "policy_loss": -0.02064557932317257, "value_loss": 0.34643667936325073, "entropy": 1.68838632106781, "explained_variance": -1.9931175708770752, "mean_reward": 0.0, "recent_episode_count": 282, "_timestamp": 1748899042.0072944, "_runtime": 3459.28790140152, "_step": 2282, "episode_reward": -19.0, "episode_count": 282, "max_reward": -17.0, "update_step": 1999, "final_test_reward": -19.0, "avg_reward_last_100_episodes": -20.09, "avg_reward_last_50_episodes": -20.42, "max_reward_achieved": -17.0, "min_reward_achieved": -21.0, "improvement_score": 0.28000000000000114, "total_training_time_minutes": 57.38962375720342, "total_episodes": 1994, "_wandb": {"runtime": 3458}}