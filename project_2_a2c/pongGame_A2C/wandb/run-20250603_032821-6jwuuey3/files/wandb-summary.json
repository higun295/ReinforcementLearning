{"update": 1999, "total_loss": 0.8977067470550537, "policy_loss": 0.004976525902748108, "value_loss": 0.8927304148674011, "entropy": 0.9953035116195679, "explained_variance": -0.0033752918243408203, "mean_reward": -0.0234375, "recent_episode_count": 550, "ppo_ratio_mean": 1.0, "clipped_fraction": 0.0, "kl_divergence": -4.256337859942505e-08, "_timestamp": 1748895565.999642, "_runtime": 6664.366739988327, "_step": 2550, "episode_reward": -21.0, "episode_count": 550, "max_reward": -17.0, "update_step": 1997, "final_test_reward": -19.0, "avg_reward_last_100_episodes": -20.37, "avg_reward_last_50_episodes": -20.46, "max_reward_achieved": -17.0, "min_reward_achieved": -21.0, "improvement_score": 0.14999999999999858, "total_training_time_minutes": 110.78142478863398, "total_episodes": 1997, "_wandb": {"runtime": 6663}}