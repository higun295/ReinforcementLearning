  0%|                                                                                          | 0/500 [00:00<?, ?it/s]C:\Users\HEEKWON\anaconda3\envs\rl_a2c\lib\site-packages\gym\utils\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
Saving model in ../model/ppo
model saved






















































































































































































































 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                             | 215/500 [12:03<15:59,  3.37s/it]
C:\Users\HEEKWON\anaconda3\envs\rl_a2c\lib\site-packages\gym\utils\passive_env_checker.py:289: UserWarning: [33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.
  logger.warn(
Traceback (most recent call last):
  File "D:\Projects\Python\ReinforcementLearning\project_2_a2c\pongGame_A2C\main.py", line 45, in <module>
    main()
  File "D:\Projects\Python\ReinforcementLearning\project_2_a2c\pongGame_A2C\main.py", line 24, in main
    rewards_history = agent.train(pw)
  File "D:\Projects\Python\ReinforcementLearning\project_2_a2c\pongGame_A2C\agent.py", line 59, in train
  File "D:\Projects\Python\ReinforcementLearning\project_2_a2c\pongGame_A2C\agent.py", line 238, in logits_action_value
    # Entropy loss can be calculated as cross-entropy over itself.
  File "C:\Users\HEEKWON\anaconda3\envs\rl_a2c\lib\site-packages\keras\src\utils\traceback_utils.py", line 65, in error_handler
    return fn(*args, **kwargs)
  File "C:\Users\HEEKWON\anaconda3\envs\rl_a2c\lib\site-packages\keras\src\engine\training.py", line 589, in __call__
    return super().__call__(*args, **kwargs)
  File "C:\Users\HEEKWON\anaconda3\envs\rl_a2c\lib\site-packages\keras\src\utils\traceback_utils.py", line 65, in error_handler
    return fn(*args, **kwargs)
  File "C:\Users\HEEKWON\anaconda3\envs\rl_a2c\lib\site-packages\keras\src\engine\base_layer.py", line 1149, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File "C:\Users\HEEKWON\anaconda3\envs\rl_a2c\lib\site-packages\keras\src\utils\traceback_utils.py", line 96, in error_handler
    return fn(*args, **kwargs)
  File "D:\Projects\Python\ReinforcementLearning\project_2_a2c\pongGame_A2C\network.py", line 41, in call
    x = self.conv4(x)
  File "C:\Users\HEEKWON\anaconda3\envs\rl_a2c\lib\site-packages\keras\src\utils\traceback_utils.py", line 65, in error_handler
    return fn(*args, **kwargs)
  File "C:\Users\HEEKWON\anaconda3\envs\rl_a2c\lib\site-packages\keras\src\engine\base_layer.py", line 1149, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File "C:\Users\HEEKWON\anaconda3\envs\rl_a2c\lib\site-packages\keras\src\utils\traceback_utils.py", line 96, in error_handler
    return fn(*args, **kwargs)
  File "C:\Users\HEEKWON\anaconda3\envs\rl_a2c\lib\site-packages\keras\src\layers\convolutional\base_conv.py", line 290, in call
    outputs = self.convolution_op(inputs, self.kernel)
  File "C:\Users\HEEKWON\anaconda3\envs\rl_a2c\lib\site-packages\keras\src\layers\convolutional\base_conv.py", line 262, in convolution_op
    return tf.nn.convolution(
  File "C:\Users\HEEKWON\anaconda3\envs\rl_a2c\lib\site-packages\tensorflow\python\util\traceback_utils.py", line 150, in error_handler
    return fn(*args, **kwargs)
  File "C:\Users\HEEKWON\anaconda3\envs\rl_a2c\lib\site-packages\tensorflow\python\util\dispatch.py", line 1260, in op_dispatch_handler
    return dispatch_target(*args, **kwargs)
  File "C:\Users\HEEKWON\anaconda3\envs\rl_a2c\lib\site-packages\tensorflow\python\ops\nn_ops.py", line 1183, in convolution_v2
    return convolution_internal(
  File "C:\Users\HEEKWON\anaconda3\envs\rl_a2c\lib\site-packages\tensorflow\python\ops\nn_ops.py", line 1316, in convolution_internal
    return op(
  File "C:\Users\HEEKWON\anaconda3\envs\rl_a2c\lib\site-packages\tensorflow\python\ops\nn_ops.py", line 2790, in _conv2d_expanded_batch
    return gen_nn_ops.conv2d(
  File "C:\Users\HEEKWON\anaconda3\envs\rl_a2c\lib\site-packages\tensorflow\python\ops\gen_nn_ops.py", line 1453, in conv2d
    _result = pywrap_tfe.TFE_Py_FastPathExecute(
KeyboardInterrupt
[‚úî] ÏòÅÏÉÅ Ï†ÄÏû• ÏôÑÎ£å: ../model/ppo/save_agent_202506030137/test_play.mp4
[‚úî] Ï†ÄÏû• ÏôÑÎ£å - Î™®Îç∏: ../model/ppo/save_agent_202506030137/model.tf, ÏòÅÏÉÅ: ../model/ppo/save_agent_202506030137/test_play.mp4, Î¶¨ÏõåÎìú: -20.0